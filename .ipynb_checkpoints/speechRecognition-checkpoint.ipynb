{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77f0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/modelscope/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-30 15:45:24,276 - modelscope - INFO - PyTorch version 1.11.0+cu115 Found.\n",
      "2023-10-30 15:45:24,279 - modelscope - INFO - Loading ast index from /home/bupt/.cache/modelscope/ast_indexer\n",
      "2023-10-30 15:45:24,630 - modelscope - INFO - Loading done! Current index file version is 1.9.4, with md5 1755177c48494333a84e454611daba4c and a total number of 945 components indexed\n"
     ]
    }
   ],
   "source": [
    "# 语音转文本功能实现 - Parameter\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"MODELSCOPE_CACHE\"):\n",
    "    os.environ.setdefault(\"MODELSCOPE_CACHE\", \"/data/ys_data/project/models/hub/\")\n",
    "if not os.environ.get(\"MODELSCOPE_MODULES_CACHE\"):\n",
    "    os.environ.setdefault(\"MODELSCOPE_MODULES_CACHE\", \"/data/ys_data/project/modelscope_modules/\")\n",
    "    \n",
    "print(os.environ.get(\"MODELSCOPE_CACHE\"))\n",
    "print(os.environ.get(\"MODELSCOPE_MODULES_CACHE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce57316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 15:45:27,795 - modelscope - WARNING - Model revision not specified, use revision: v1.2.4\n",
      "2023-10-30 15:45:28,517 - modelscope - WARNING - Model revision not specified, use revision: v1.2.0\n",
      "2023-10-30 15:45:29,142 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2023-10-30 15:45:30,437 - modelscope - WARNING - Model revision not specified, use revision: v0.2.2\n"
     ]
    }
   ],
   "source": [
    "# 模型下载\n",
    "\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "local_dir_root = \"/data/ys_data/project/models/\"\n",
    "\n",
    "model_dir_paraformer = snapshot_download('damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch', cache_dir=local_dir_root)\n",
    "model_dir_vad = snapshot_download('damo/speech_fsmn_vad_zh-cn-16k-common-pytorch', cache_dir=local_dir_root)\n",
    "model_dir_punc = snapshot_download('damo/punc_ct-transformer_cn-en-common-vocab471067-large', cache_dir=local_dir_root)\n",
    "model_dir_lm = snapshot_download('damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch', cache_dir=local_dir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "291f043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 15:46:23,513 - modelscope - INFO - initiate model from /data/ys_data/project/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-10-30 15:46:23,514 - modelscope - INFO - initiate model from location /data/ys_data/project/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch.\n",
      "2023-10-30 15:46:23,515 - modelscope - INFO - initialize model from /data/ys_data/project/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-10-30 15:46:23,517 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-10-30 15:46:23,517 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-10-30 15:46:23,517 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/data/ys_data/project/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch'}. trying to build by task and model information.\n",
      "2023-10-30 15:46:23,518 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-10-30 15:46:24,524 - modelscope - WARNING - Model revision not specified, use revision: v1.2.4\n",
      "Downloading:   0%|          | 0.00/859M [00:00<?, ?B/s]\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 本地模型路径\n",
    "local_dir_paraformer = model_dir_paraformer\n",
    "local_dir_vad = model_dir_vad\n",
    "local_dir_punc = model_dir_punc\n",
    "local_dir_lm = model_dir_lm\n",
    "\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# 管道初始化\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model=local_dir_paraformer,\n",
    "    vad_model=local_dir_vad,\n",
    "    punc_model=local_dir_punc,\n",
    "    lm_model=local_dir_lm,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "\n",
    "# 输入音频，即待识别样本\n",
    "audio_in = 'https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_vad_punc_example.wav'\n",
    "\n",
    "# 输出为转化完的文本\n",
    "results = inference_pipeline(audio_in=audio_in, batch_size_token=5000, batch_size_token_threshold_s=40, max_single_segment_time=6000)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_dir_paraformer)\n",
    "print(local_dir_vad)\n",
    "print(local_dir_punc)\n",
    "print(local_dir_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.pipelines.builder import *\n",
    "model = normalize_model_input(\n",
    "    local_dir_paraformer,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = read_config(model, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_props = cfg.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdaa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_props['model'] = model\n",
    "pipeline_props['device'] = 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363da8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfigDict(pipeline_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ConfigDict(pipeline_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "registry.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0da881",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = (registry.name.upper(), 'auto-speech-recognition', 'asr-inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope.utils.import_utils import LazyImportModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LazyImportModule.import_module(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = cfg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e25f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_type = args.pop('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b83ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cls = registry.get(obj_type, 'auto-speech-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(obj_cls, '_instantiate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad636e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope",
   "language": "python",
   "name": "modelscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
