{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77f0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/modelscope/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-30 19:15:36,753 - modelscope - INFO - PyTorch version 1.11.0+cu115 Found.\n",
      "2023-10-30 19:15:36,755 - modelscope - INFO - Loading ast index from /home/bupt/.cache/modelscope/ast_indexer\n",
      "2023-10-30 19:15:36,814 - modelscope - INFO - Loading done! Current index file version is 1.9.4, with md5 1755177c48494333a84e454611daba4c and a total number of 945 components indexed\n"
     ]
    }
   ],
   "source": [
    "# 语音转文本功能实现 - Parameter\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a557b35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/ys_data/project/models/hub/\n",
      "/data/ys_data/project/modelscope_modules/\n"
     ]
    }
   ],
   "source": [
    "# 设置环境变量\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"MODELSCOPE_CACHE\"):\n",
    "    os.environ.setdefault(\"MODELSCOPE_CACHE\", \"/data/ys_data/project/models/hub/\")\n",
    "if not os.environ.get(\"MODELSCOPE_MODULES_CACHE\"):\n",
    "    os.environ.setdefault(\"MODELSCOPE_MODULES_CACHE\", \"/data/ys_data/project/modelscope_modules/\")\n",
    "    \n",
    "print(os.environ.get(\"MODELSCOPE_CACHE\"))\n",
    "print(os.environ.get(\"MODELSCOPE_MODULES_CACHE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce57316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 19:15:40,802 - modelscope - WARNING - Model revision not specified, use revision: v1.2.4\n",
      "Downloading: 100%|██████████| 10.9k/10.9k [00:00<00:00, 906kB/s]\n",
      "Downloading: 100%|██████████| 408k/408k [00:00<00:00, 6.51MB/s]\n",
      "Downloading: 100%|██████████| 55.5k/55.5k [00:00<00:00, 3.38MB/s]\n",
      "Downloading: 100%|██████████| 790/790 [00:00<00:00, 183kB/s]\n",
      "Downloading: 100%|██████████| 91.0/91.0 [00:00<00:00, 30.0kB/s]\n",
      "Downloading: 100%|██████████| 725/725 [00:00<00:00, 247kB/s]\n",
      "Downloading: 100%|█████████▉| 859M/859M [01:18<00:00, 11.5MB/s]\n",
      "Downloading: 100%|██████████| 30.8k/30.8k [00:00<00:00, 1.00MB/s]\n",
      "Downloading: 100%|██████████| 7.90M/7.90M [00:00<00:00, 11.0MB/s]\n",
      "Downloading: 100%|██████████| 48.7k/48.7k [00:00<00:00, 2.96MB/s]\n",
      "2023-10-30 19:17:04,349 - modelscope - WARNING - Model revision not specified, use revision: v1.2.0\n",
      "Downloading: 100%|██████████| 518/518 [00:00<00:00, 96.3kB/s]\n",
      "Downloading: 100%|██████████| 15.1k/15.1k [00:00<00:00, 2.64MB/s]\n",
      "Downloading: 100%|██████████| 27.3k/27.3k [00:00<00:00, 1.99MB/s]\n",
      "Downloading: 100%|██████████| 7.85k/7.85k [00:00<00:00, 1.67MB/s]\n",
      "Downloading: 100%|██████████| 1.64M/1.64M [00:00<00:00, 6.10MB/s]\n",
      "Downloading: 100%|██████████| 1.19k/1.19k [00:00<00:00, 213kB/s]\n",
      "Downloading: 100%|██████████| 2.16M/2.16M [00:00<00:00, 10.2MB/s]\n",
      "2023-10-30 19:17:06,791 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "Downloading: 100%|██████████| 5.66M/5.66M [00:00<00:00, 11.0MB/s]\n",
      "Downloading: 100%|██████████| 522/522 [00:00<00:00, 92.6kB/s]\n",
      "Downloading: 100%|██████████| 39.6M/39.6M [00:05<00:00, 7.54MB/s]\n",
      "Downloading: 100%|██████████| 10.8M/10.8M [00:01<00:00, 10.7MB/s]\n",
      "Downloading: 100%|█████████▉| 1.05G/1.05G [01:37<00:00, 11.5MB/s]\n",
      "Downloading: 100%|██████████| 5.66M/5.66M [00:00<00:00, 10.0MB/s]\n",
      "Downloading: 100%|██████████| 863/863 [00:00<00:00, 150kB/s]\n",
      "Downloading: 100%|██████████| 8.32k/8.32k [00:00<00:00, 1.39MB/s]\n",
      "Downloading: 100%|██████████| 151k/151k [00:00<00:00, 4.77MB/s]\n",
      "2023-10-30 19:18:58,106 - modelscope - WARNING - Model revision not specified, use revision: v0.2.2\n",
      "Downloading: 100%|██████████| 538/538 [00:00<00:00, 91.7kB/s]\n",
      "Downloading: 100%|██████████| 226M/226M [00:22<00:00, 10.7MB/s] \n",
      "Downloading: 100%|██████████| 53.1k/53.1k [00:00<00:00, 2.85MB/s]\n",
      "Downloading: 100%|██████████| 17.3k/17.3k [00:00<00:00, 4.68MB/s]\n",
      "Downloading: 100%|██████████| 7.90M/7.90M [00:00<00:00, 11.1MB/s]\n",
      "Downloading: 100%|██████████| 34.0k/34.0k [00:00<00:00, 2.38MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 模型下载\n",
    "\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "\n",
    "local_dir_root = \"/data/ys_data/project/models/hub/\"\n",
    "\n",
    "model_dir_paraformer = snapshot_download('damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch', cache_dir=local_dir_root)\n",
    "model_dir_vad = snapshot_download('damo/speech_fsmn_vad_zh-cn-16k-common-pytorch', cache_dir=local_dir_root)\n",
    "model_dir_punc = snapshot_download('damo/punc_ct-transformer_cn-en-common-vocab471067-large', cache_dir=local_dir_root)\n",
    "model_dir_lm = snapshot_download('damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch', cache_dir=local_dir_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "291f043b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 19:22:33,174 - modelscope - INFO - initiate model from /data/ys_data/project/models/hub/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-10-30 19:22:33,175 - modelscope - INFO - initiate model from location /data/ys_data/project/models/hub/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch.\n",
      "2023-10-30 19:22:33,176 - modelscope - INFO - initialize model from /data/ys_data/project/models/hub/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-10-30 19:22:33,179 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-10-30 19:22:33,179 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-10-30 19:22:33,180 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/data/ys_data/project/models/hub/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch'}. trying to build by task and model information.\n",
      "2023-10-30 19:22:33,180 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-10-30 19:22:33,657 - modelscope - INFO - loading vad model from /data/ys_data/project/models/hub/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch ...\n",
      "2023-10-30 19:22:33,658 - modelscope - INFO - loading punctuation model from /data/ys_data/project/models/hub/damo/punc_ct-transformer_cn-en-common-vocab471067-large ...\n",
      "2023-10-30 19:22:33,659 - modelscope - INFO - loading language model from /data/ys_data/project/models/hub/damo/speech_transformer_lm_zh-cn-common-vocab8404-pytorch ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "2023-10-30 19:23:05,478 (__init__:113) DEBUG: Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "2023-10-30 19:23:05,978 (__init__:146) DEBUG: Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.556 seconds.\n",
      "2023-10-30 19:23:06,037 (__init__:164) DEBUG: Loading model cost 0.556 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2023-10-30 19:23:06,039 (__init__:166) DEBUG: Prefix dict has been built successfully.\n",
      "2023-10-30 19:23:26,463 - modelscope - INFO - Decoding with wav files ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size_token:  5000\n",
      "time cost vad:  0.1968517303466797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "2023-10-30 19:23:28,911 - modelscope - INFO - Computing the result of ASR ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time cost asr:  1.9114601612091064\n",
      "time cost punc:  0.06557083129882812\n",
      "{'text': '正是因为存在绝对正义，所以我们接受现实的相对正义。但是不要因为现实的相对正义，我们就认为这个世界没有正义。因为如果当你认为这个世界没有正义。', 'text_postprocessed': '正 是 因 为 存 在 绝 对 正 义 所 以 我 们 接 受 现 实 的 相 对 正 义 但 是 不 要 因 为 现 实 的 相 对 正 义 我 们 就 认 为 这 个 世 界 没 有 正 义 因 为 如 果 当 你 认 为 这 个 世 界 没 有 正 义', 'time_stamp': [[430, 670], [670, 810], [810, 1030], [1030, 1130], [1130, 1330], [1330, 1510], [1510, 1670], [1670, 1810], [1810, 1970], [1970, 2210], [2250, 2390], [2390, 2490], [2490, 2570], [2570, 2710], [2710, 2950], [2970, 3210], [3310, 3550], [3570, 3730], [3730, 3830], [3830, 3970], [3970, 4150], [4150, 4270], [4270, 4535], [5290, 5470], [5470, 5610], [5610, 5710], [5710, 5910], [5910, 6070], [6070, 6230], [6230, 6470], [6470, 6650], [6650, 6750], [6750, 6950], [6950, 7130], [7130, 7250], [7250, 7490], [7490, 7590], [7590, 7710], [7710, 7910], [7910, 8070], [8070, 8290], [8290, 8430], [8430, 8550], [8550, 8710], [8710, 8950], [9050, 9290], [9370, 9550], [9550, 9790], [9790, 9965], [10600, 10760], [10760, 10900], [10900, 11120], [11120, 11300], [11300, 11400], [11400, 11580], [11580, 11700], [11700, 11800], [11800, 11920], [11920, 12020], [12020, 12160], [12160, 12320], [12320, 12440], [12440, 12560], [12560, 12740], [12740, 12915]], 'sentences': [{'text': '正是因为存在绝对正义，', 'start': 430, 'end': 2210, 'text_seg': '正 是 因 为 存 在 绝 对 正 义 ', 'ts_list': [[430, 670], [670, 810], [810, 1030], [1030, 1130], [1130, 1330], [1330, 1510], [1510, 1670], [1670, 1810], [1810, 1970], [1970, 2210]]}, {'text': '所以我们接受现实的相对正义。', 'start': 2210, 'end': 4535, 'text_seg': '所 以 我 们 接 受 现 实 的 相 对 正 义 ', 'ts_list': [[2250, 2390], [2390, 2490], [2490, 2570], [2570, 2710], [2710, 2950], [2970, 3210], [3310, 3550], [3570, 3730], [3730, 3830], [3830, 3970], [3970, 4150], [4150, 4270], [4270, 4535]]}, {'text': '但是不要因为现实的相对正义，', 'start': 4535, 'end': 7490, 'text_seg': '但 是 不 要 因 为 现 实 的 相 对 正 义 ', 'ts_list': [[5290, 5470], [5470, 5610], [5610, 5710], [5710, 5910], [5910, 6070], [6070, 6230], [6230, 6470], [6470, 6650], [6650, 6750], [6750, 6950], [6950, 7130], [7130, 7250], [7250, 7490]]}, {'text': '我们就认为这个世界没有正义。', 'start': 7490, 'end': 9965, 'text_seg': '我 们 就 认 为 这 个 世 界 没 有 正 义 ', 'ts_list': [[7490, 7590], [7590, 7710], [7710, 7910], [7910, 8070], [8070, 8290], [8290, 8430], [8430, 8550], [8550, 8710], [8710, 8950], [9050, 9290], [9370, 9550], [9550, 9790], [9790, 9965]]}, {'text': '因为如果当你认为这个世界没有正义。', 'start': 9965, 'end': 12915, 'text_seg': '因 为 如 果 当 你 认 为 这 个 世 界 没 有 正 义 ', 'ts_list': [[10600, 10760], [10760, 10900], [10900, 11120], [11120, 11300], [11300, 11400], [11400, 11580], [11580, 11700], [11700, 11800], [11800, 11920], [11920, 12020], [12020, 12160], [12160, 12320], [12320, 12440], [12440, 12560], [12560, 12740], [12740, 12915]]}]}\n"
     ]
    }
   ],
   "source": [
    "# 本地模型路径\n",
    "local_dir_paraformer = model_dir_paraformer\n",
    "local_dir_vad = model_dir_vad\n",
    "local_dir_punc = model_dir_punc\n",
    "local_dir_lm = model_dir_lm\n",
    "\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# 管道初始化\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model=local_dir_paraformer,\n",
    "    vad_model=local_dir_vad,\n",
    "    punc_model=local_dir_punc,\n",
    "    lm_model=local_dir_lm,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "\n",
    "# 输入音频，即待识别样本\n",
    "audio_in = 'https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_vad_punc_example.wav'\n",
    "\n",
    "# 输出为转化完的文本\n",
    "results = inference_pipeline(audio_in=audio_in, batch_size_token=5000, batch_size_token_threshold_s=40, max_single_segment_time=6000)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad636e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope",
   "language": "python",
   "name": "modelscope"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
